
Deployment 

# Awareness Architecture 

![](https://zisoft-public.s3-eu-west-1.amazonaws.com/zisoft.vpd+(1).png)
## Web Server :
Web Server has focused on high performance, high concurrency and low memory usage web server functionality, like load balancing, caching, access and bandwidth control, and the ability to integrate efficiently with a variety of applications

  1.   HTTP Handler
  2.   Serving Static Content
  3.   Web Server Reverse Proxy
  4.   Web Server Content Caching
  5.   Compression and Decompression
  6.   Secure Connect with SSL CA  

## UI Server ( Angular ) : 

Frontend  part of the application that users can see and interact with directly in order to receive the backend capabilities of the system. It involves everything that the user can see, touch and experience.

## Web Application Server ( Laravel) :

Laravel is a web application framework with expressive, elegant syntax. ... Laravel attempts to take the pain out of development by easing common tasks used in the majority of web projects, such as authentication, routing, sessions, and caching

- AUTHORIZATION TECHNIQUE :
    Laravel  provides a simple way to organize authorization logic and control access to resources.
 - OBJECT-ORIENTED LIBRARIES :
  pre-installed libraries to implement  many advanced features, such as checking active users,                     Bcrypt hashing, password reset, CSRF (Cross-site Request Forgery) protection, and encryption.

-ARTISAN : 
Developer has to usually interact with the Laravel framework using a command line that creates and handles the Laravel project environment. 
-MVC SUPPORT :
Supports MVC Architecture ensuring clarity between logic and presentation. MVC helps in improving the performance, allows better documentation, and has multiple built-in functionalities.


-SECURITY :
Ues Bcrypt hashing algorithm for generating an encrypted representation of a password. Laravel uses prepared SQL statements which make injection attacks unimaginable. Along with this, Laravel provides a simple way to escape user input to avoid user injection of  tag.
-SSO Integration :
One-click sign-in: Allows collaborators to sign in from your SSO provider without maintaining a separate username and password.
Automatic provisioning: Allows authorized users to create account when they require access.

-LDAP Integration : 
 LDAP integration allows your instance to use your existing LDAP server as the master source of user data.Administrators integrate with a Lightweight Directory Access Protocol (LDAP) directory to streamline the user login process and to automate administrative tasks such as creating users and assigning them role

## Analytics server  ( Metabase ) :
Analyzing data and presenting actionable information which helps executives, managers and other corporate users make informed training/phishing decisions.

    -  BI : information management tool that is used to track KPIs, metrics, and other key data points relevant to a business, department, or specific process. Through the use of data visualizations, dashboards simplify complex data sets to provide users with at a glance awareness of current performance.

## Cron server :
Laravel command scheduler allows for the fluent and expressive defining of command schedule within Laravel itself, and only a single Cron entry is needed on the server

## Database Server ( MariaDB) : 
MariaDB   open source relational database management system (DBMS) that is a compatible drop-in replacement for the widely used MySQL database technology.
MariaDB sports faster and safer replication with updates being up to 2x faster than with traditional MySQL Replication setups. ... MariaDB replication is backward compatible with MySQL servers,


# Awareness HA Deployment

## NFS: RHEL/CentOS/ Debian/Ubuntu 
==============================================================================


1.  **NFS** allows local access to remote files.
2.  It uses standard **client**/**server** architecture for file sharing
    between all \***nix** based machines.
3.  With **NFS** it is not necessary that both machines run on the same
    **OS**.

![](https://awareness-docs.s3.us-east-2.amazonaws.com/_static/images/nfs.png)
4.  With the help of **NFS** we can configure **centralized storage**
    solutions.
5.  Users get their **data** irrespective of physical location.
6.  No manual **refresh** needed for new files.
7.  Newer version of **NFS** also supports **acl**, **pseudo** root
    mounts.
8.  Can be secured with **Firewalls** and **Kerberos**.

##### NFS Services

Its a **System V-launched** service. The **NFS** server package includes
three facilities, included in the **portmap** and **nfs-utils**
packages.

1.  **portmap** : It maps calls made from other machines to the correct
    **RPC** service (not required with **NFSv4**).
2.  **nfs**: It translates remote **file sharing** requests into
    requests on the local file system.
3.  **rpc.mountd**: This service is responsible for **mounting** and
    **unmounting** of file systems.

##### Important Files for NFS Configuration

1.  **/etc/exports** : Its a main configuration file of **NFS**, all
    exported **files** and **directories** are defined in this file at
    the **NFS Server** end.
2.  **/etc/fstab** : To mount a **NFS directory** on your system across
    the **reboots**, we need to make an entry in **/etc/fstab**.
3.  **/etc/sysconfig/nfs** : Configuration file of **NFS** to control on
    which port **rpc** and other services are **listening**.

#### Setup and Configure NFS Mounts on Linux Server

To setup **NFS** mounts, we’ll be needing at least two
**Linux**/**Unix** machines. Here in this tutorial, I’ll be using two
servers.

1.  **NFS Server**: nfsserver.example.com with IP-**192.168.0.100**
2.  **NFS Client** : nfsclient.example.com with IP-**192.168.0.101**

##### Installing NFS Server and NFS Client

We need to install **NFS** packages on our **NFS Server** as well as on
**NFS Client** machine. We can install it via “**yum**” (**Red Hat**
Linux) and “**apt-get**” (**Debian** and **Ubuntu**) package installers.

    [root@nfsserver ~]# yum install nfs-utils nfs-utils-lib
    [root@nfsserver ~]# yum install portmap (not required with NFSv4)

    [root@nfsserver ~]# apt-get install nfs-utils nfs-utils-lib

Now start the **services** on both machines.

    [root@nfsserver ~]# /etc/init.d/portmap start
    [root@nfsserver ~]# /etc/init.d/nfs start
    [root@nfsserver ~]# chkconfig --level 35 portmap on
    [root@nfsserver ~]# chkconfig --level 35 nfs on

After installing packages and starting services on both the machines, we
need to configure both the machines for file sharing.

#### Setting Up the NFS Server

First we will be configuring the **NFS** server.

##### Configure Export directory

For sharing a directory with **NFS**, we need to make an entry in
“**/etc/exports**” configuration file. Here I’ll be creating a new
directory named “**nfsshare**” in “**/**” partition to share with
**client server**, you can also share an already existing directory with
NFS.

    [root@nfsserver ~]# mkdir /nfsshare

Now we need to make an entry in “**/etc/exports**” and **restart** the
services to make our directory shareable in the network.

    [root@nfsserver ~]# vi /etc/exports

    /nfsshare 192.168.0.101(rw,sync,no_root_squash)

In the above example, there is a directory in **/** partition named
“**nfsshare**” is being shared with client IP “**192.168.0.101**” with
**read** and **write** (**rw**) privilege, you can also use **hostname**
of the client in the place of **IP** in above example.

##### NFS Options

Some other options we can use in “**/etc/exports**” file for file
sharing is as follows.

1.  **ro**: With the help of this option we can provide **read only
    access** to the shared files i.e **client** will only be able to
    **read**.
2.  **rw**: This option allows the **client server** to both **read**
    and **write** access within the shared directory.
3.  **sync**: Sync confirms requests to the shared directory only once
    the **changes** have been committed.
4.  **no\_subtree\_check**: This option prevents the **subtree**
    checking. When a shared directory is the subdirectory of a larger
    file system, **nfs** performs scans of every directory above it, in
    order to verify its permissions and details. Disabling the
    **subtree** check may increase the reliability of **NFS**, but
    reduce **security**.
5.  **no\_root\_squash**: This phrase allows **root** to **connect** to
    the designated directory.

For more options with “**/etc/exports**“, you are recommended to read
the **man pages** for **export**.

#### Setting Up the NFS Client

After configuring the **NFS** server, we need to **mount** that shared
directory or partition in the **client** server.

##### Mount Shared Directories on NFS Client

Now at the **NFS client** end, we need to **mount** that directory in
our server to access it locally. To do so, first we need to find out
that shares available on the remote server or NFS Server.

    [root@nfsclient ~]# showmount -e 192.168.0.100

    Export list for 192.168.0.100:
    /nfsshare 192.168.0.101

Above command shows that a directory named “**nfsshare**” is available
at “**192.168.0.100**” to share with your server.

##### Mount Shared NFS Directory

To **mount** that shared **NFS** directory we can use following mount
command.

    [root@nfsclient ~]# mount -t nfs 192.168.0.100:/nfsshare /mnt/nfsshare

The above command will mount that shared directory in
“**/mnt/nfsshare**” on the client server. You can verify it following
command.

    [root@nfsclient ~]# mount | grep nfs

    sunrpc on /var/lib/nfs/rpc_pipefs type rpc_pipefs (rw)
    nfsd on /proc/fs/nfsd type nfsd (rw)
    192.168.0.100:/nfsshare on /mnt type nfs (rw,addr=192.168.0.100)

The above mount command mounted the **nfs shared directory** on to **nfs
client** temporarily, to mount an NFS directory **permanently** on your
system across the **reboots**, we need to make an entry in
“**/etc/fstab**“.

    [root@nfsclient ~]# vi /etc/fstab

Add the following new line as shown below.

    192.168.0.100:/nfsshare /mnt  nfs defaults 0 0

#### Test the Working of NFS Setup

We can test our **NFS server setup** by creating a **test file** on the
server end and check its availability at **nfs client** side or
vice-versa.

##### At the nfsserver end

I have created a new text file named “**nfstest.txt**’ in that shared
directory.

    [root@nfsserver ~]# cat > /nfsshare/nfstest.txt

    This is a test file to test the working of NFS server setup.

##### At the nfsclient end

Go to that shared directory in **client server** and you’ll find that
shared file without any manual refresh or service restart.

    [root@nfsclient]# ll /mnt/nfsshare
    total 4
    -rw-r--r-- 1 root root 61 Sep 21 21:44 nfstest.txt
    root@nfsclient ~]# cat /mnt/nfsshare/nfstest.txt
    This is a test file to test the working of NFS server setup.

#### Removing the NFS Mount

If you want to **unmount** that shared directory from your server after
you are done with the file sharing, you can simply **unmount** that
particular directory with “**umount**” command. See this example below.

    root@nfsclient ~]# umount /mnt/nfsshare

You can see that the mounts were removed by then looking at the
filesystem again.

    [root@nfsclient ~]# df -h -F nfs

You’ll see that those shared directories are not available any more.

##### Important commands for NFS

Some more important commands for **NFS**.

1.  **showmount -e** : Shows the available **shares** on your local
    machine
2.  **showmount -e** **\<server-ip or hostname\>**: Lists the available
    **shares** at the **remote** server
3.  **showmount -d** : Lists all the **sub directories**
4.  **exportfs -v** : Displays a list of shares **files** and
    **options** on a server
5.  **exportfs -a** : Exports all shares listed in **/etc/exports**, or
    given name
6.  **exportfs -u** : Unexports all shares listed in **/etc/exports**,
    or given name
7.  **exportfs -r** : Refresh the server’s list after modifying
    **/etc/exports**




## Create a swarm Cluster 
===========================

After you complete the (https://docs.docker.com/engine/swarm/swarm-tutorial/) steps,
you’re ready to create a swarm. Make sure the Docker Engine daemon is
started on the host machines.

### Init Swarm Manager Node  
=============================



1.  Open a terminal and ssh into the machine where you want to run your
    manager node. This tutorial uses a machine named
    `manager1`. If you use Docker Machine, you can
    connect to it via SSH using the following command:

    ```
    $ docker-machine ssh manager1
    ```

2.  Run the following command to create a new swarm:

    ```
    $ docker swarm init --advertise-addr <MANAGER-IP>
    ```

    > **Note**: If you are using Docker Desktop for Mac or Docker
    > Desktop for Windows to test single-node swarm, simply run
    > `docker swarm init` with no arguments. There
    > is no need to specify `--advertise-addr` in
    > this case. To learn more, see the topic on how to [Use Docker
    > Desktop or Mac or Docker Desktop for
    > Windows](https://docs.docker.com/engine/swarm/swarm-tutorial/#use-docker-for-mac-or-docker-for-windows)
    > with Swarm.

    In the tutorial, the following command creates a swarm on the
    `manager1` machine:

    ```
    $ docker swarm init --advertise-addr 192.168.99.100
    ```
    Swarm initialized: current node (dxn1zf6l61qsb1josjja83ngz) is now a manager.

    To add a worker to this swarm, run the following command:
     
        ```
        $ docker swarm join \
        --token SWMTKN-1-49nj1cmql0jkz5s954yi3oex3nedyz0fb0xx14ie39trti4wxv-8vxv8rssmk743ojnwacrr2e7c \
        192.168.99.100:2377
        ```
    To add a manager to this swarm, run 'docker swarm join-token manager' and follow the instructions.
   

    The `--advertise-addr` flag configures the
    manager node to publish its address as
    `192.168.99.100`. The other nodes in the swarm
    must be able to access the manager at the IP address.

    The output includes the commands to join new nodes to the swarm.
    Nodes will join as managers or workers depending on the value for
    the `--token` flag.

3.  Run `docker info` to view the current state of
    the swarm:

    ```
    $ docker info

    Containers: 2
    Running: 0
    Paused: 0
    Stopped: 2
      ...snip...
    Swarm: active
      NodeID: dxn1zf6l61qsb1josjja83ngz
      Is Manager: true
      Managers: 1
      Nodes: 1
      ...snip...
    ```

4.  Run the `docker node ls` command to view
    information about nodes:

    ```
    $ docker node ls

    ID                           HOSTNAME  STATUS  AVAILABILITY  MANAGER STATUS
    dxn1zf6l61qsb1josjja83ngz *  manager1  Ready   Active        Leader
    ```

    The `*` next to the node ID indicates that
    you’re currently connected on this node.

    Docker Engine swarm mode automatically names the node for the
    machine host name.


### Add nodes to the swarm 
=============================


1.  Open a terminal and ssh into the machine where you want to run a
    worker node. This tutorial uses the name
    `worker1`.

2.  Run the command produced by the
    `docker swarm init` output from the [Create a
    swarm](https://docs.docker.com/engine/swarm/swarm-tutorial/create-swarm/)
    tutorial step to create a worker node joined to the existing swarm:

    ```
    $ docker swarm join \
      --token  SWMTKN-1-49nj1cmql0jkz5s954yi3oex3nedyz0fb0xx14ie39trti4wxv-8vxv8rssmk743ojnwacrr2e7c \
      192.168.99.100:2377
    ```

    This node joined a swarm as a worker.


    If you don’t have the command available, you can run the following
    command on a manager node to retrieve the join command for a worker:

    ```
    $ docker swarm join-token worker
    ```
    To add a worker to this swarm, run the following command:
    ```
        docker swarm join \
        --token SWMTKN-1-49nj1cmql0jkz5s954yi3oex3nedyz0fb0xx14ie39trti4wxv-8vxv8rssmk743ojnwacrr2e7c \
        192.168.99.100:2377
    ```

3.  Open a terminal and ssh into the machine where you want to run a
    second worker node. This tutorial uses the name
    `worker2`.

4.  Run the command produced by the
    `docker swarm init` output from the [Create a
    swarm](https://docs.docker.com/engine/swarm/swarm-tutorial/create-swarm/)
    tutorial step to create a second worker node joined to the existing
    swarm:

    ```
    $ docker swarm join \
      --token SWMTKN-1-49nj1cmql0jkz5s954yi3oex3nedyz0fb0xx14ie39trti4wxv-8vxv8rssmk743ojnwacrr2e7c \
      192.168.99.100:2377
    ```
   
 This node joined a swarm as a worker.
   
5.  Open a terminal and ssh into the machine where the manager node runs
    and run the `docker node ls` command to see the
    worker nodes:

     ```
     $ docker node ls

    ID                           HOSTNAME  STATUS  AVAILABILITY  MANAGER STATUS
    03g1y59jwfg7cf99w4lt0f662    worker2   Ready   Active
    9j68exjopxe7wfl6yuxml7a7j    worker1   Ready   Active
    dxn1zf6l61qsb1josjja83ngz *  manager1  Ready   Active        Leader
    ```

    The `MANAGER` column identifies the manager
    nodes in the swarm. The empty status in this column for
    `worker1` and `worker2`
    identifies them as worker nodes.

    Swarm management commands like `docker node ls`
    only work on manager nodes.


## Clone Zisoft awareness  project

   Run the command where /zisoft-ha/ is shared-FS:

    $ cd /zisoft-ha/
    $ git clone https://gitlab.com/zisoft/awareness.git
    $ cd awareness
    $ zisoft build --docker --sass --app --ui --composer
    $ zisoft package
    $ zisoft deploy --prod
    
## Deploy Zisoft awareness offline project

   Run the command :

    $ cd /zisoft-ha/
    $ zisoft deploy --prod
 
# Awareness Offline Deployment


## Prerequisites

1.  Docker swarm mode  active :
    
  Run the command :


    $ docker info

Check if swarm mode is active


![](https://awareness-docs.s3.us-east-2.amazonaws.com/_static/images/swarm-active.png)

2.  Nodejs, Npm ,Unzip Package installed.

3.  Offline zisoft-xxxxxxx.Zip file downloaded from release artifacts.


## Extract zisoft-xxxxxxx.Zip file 

   Run the command :

    $ unzip zisoft-xxxxxxx.zip

## Load Zisoft awareness docker images

  Run the command :

    $ cd zisoft-xxxxxxx
    $ zisoft load 

## Deploy Zisoft awareness offline project

   Run the command :

    $ zisoft deploy --offline
 


 
# Awareness SMTP Server


A fullstack but simple mail server (smtp, imap, antispam, antivirus...).
Only configuration files, no SQL database. Keep it simple and versioned.
Easy to deploy and upgrade.


- [Postfix](http://www.postfix.org) with smtp or ldap auth
- [Dovecot](https://www.dovecot.org) for sasl, imap (and optional pop3) with ssl support, with ldap auth and sieve.
- saslauthd with ldap auth
- [Amavis](https://www.amavis.org/)
- [Spamassasin](http://spamassassin.apache.org/) supporting custom rules
- [ClamAV](https://www.clamav.net/) with automatic updates
- [OpenDKIM](http://www.opendkim.org)
- [OpenDMARC](https://github.com/trusteddomainproject/OpenDMARC)
- [Fail2ban](https://www.fail2ban.org/wiki/index.php/Main_Page)
- [Fetchmail](http://www.fetchmail.info/fetchmail-man.html)
- [Postscreen](http://www.postfix.org/POSTSCREEN_README.html)
- [Postgrey](https://postgrey.schweikert.ch/)
- basic [Sieve support](https://github.com/tomav/docker-mailserver/wiki/Configure-Sieve-filters) using dovecot
- [LetsEncrypt](https://letsencrypt.org/) and self-signed certificates
- persistent data and state (but think about backups!)
- [Automated builds on docker hub](https://hub.docker.com/r/tvial/docker-mailserver/)
- Plus addressing (a.k.a. [extension delimiters](http://www.postfix.org/postconf.5.html#recipient_delimiter))
  works out of the box: email for `you+extension@example.com` go to `you@example.com`


## Requirements

Recommended:
- 1 CPU
- 1-2GB RAM
- Swap enabled for the container

Minimum:
- 1 CPU
- 512MB RAM

#### Create a docker-compose environment

- Edit the files `.env` and `env-mailserver` to your liking:
  - `.env` contains the configuration for docker-compose
  - `env-mailserver` contains the configuration for the mailserver container
  - These files supports only simple `VAR=VAL` lines (see [Documentation](https://docs.docker.com/compose/env-file/)).
  - Don't quote your values.
  - Variable substitution is *not* supported (e.g. `OVERRIDE_HOSTNAME=$HOSTNAME.$DOMAINNAME`).
- Install [docker-compose](https://docs.docker.com/compose/) in the version `1.7` or higher.


#### Start Container
    docker-compose up -d mail

#### Create your mail accounts

    ./setup.sh email add <user@domain> [<password>]

#### Generate DKIM keys

    ./setup.sh config dkim

Now the keys are generated, you can configure your DNS server by just pasting the content of `config/opendkim/keys/domain.tld/mail.txt` in your `domain.tld.hosts` zone.

#### Restart and update the container

    docker-compose down
    docker-compose up -d mail

You're done!

And don't forget to have a look at the remaining functions of the `setup.sh` script

#### SPF/Forwarding Problems

If you got any problems with SPF and/or forwarding mails, give [SRS](https://github.com/roehling/postsrsd/blob/master/README.md) a try. You enable SRS by setting `ENABLE_SRS=1`. See the variable description for further information.


`restart: always` ensures that the mail server container (and Filebeat/ELK containers when using the mail server together with ELK stack) is automatically restarted by Docker in cases like a Docker service or host restart or container exit.



1. A connection *may* be secured over TLS when both ends support `STARTTLS`. On ports 110, 143 and 587, `docker-mailserver` will reject a connection that cannot be secured. Port 25 is [required](https://serverfault.com/questions/623692/is-it-still-wrong-to-require-starttls-on-incoming-smtp-messages) to support insecure connections.
2. Receives email and filters for spam and viruses. For submitting outgoing mail you should prefer the submission ports(465, 587), which require authentication. Unless a relay host is configured, outgoing email will leave the server via port 25(thus outbound traffic must not be blocked by your provider or firewall).
3. A submission port since 2018, [RFC 8314](https://tools.ietf.org/html/rfc8314). Originally a secure variant of port 25.

##### Examples with just the relevant environmental variables:

```yaml
version: '2'

services:
  mail:
    image: entrench/smtp:3.1.0.0
    hostname: mail
    domainname: domain.com
    container_name: mail
    ports:
      - "25:25"
      - "143:143"
      - "587:587"
      - "993:993"
    volumes:
      - maildata:/var/mail
      - mailstate:/var/mail-state
      - maillogs:/var/log/mail
      - ./config/:/tmp/docker-mailserver/
    environment:
      - ENABLE_SPAMASSASSIN=1
      - SPAMASSASSIN_SPAM_TO_INBOX=1
      - ENABLE_CLAMAV=1
      - ENABLE_FAIL2BAN=1
      - ENABLE_POSTGREY=1
      - ONE_DIR=1
      - DMS_DEBUG=0
    cap_add:
      - NET_ADMIN
      - SYS_PTRACE

volumes:
  maildata:
    driver: local
  mailstate:
    driver: local
  maillogs:
    driver: local
```

__for ldap setup__:

```yaml
version: '2'

services:
  mail:
    image: entrench/smtp:3.1.0.0
    hostname: mail
    domainname: domain.com
    container_name: mail
    ports:
      - "25:25"
      - "143:143"
      - "587:587"
      - "993:993"
    volumes:
      - maildata:/var/mail
      - mailstate:/var/mail-state
      - maillogs:/var/log/mail
      - ./config/:/tmp/docker-mailserver/
    environment:
      - ENABLE_SPAMASSASSIN=1
      - SPAMASSASSIN_SPAM_TO_INBOX=1
      - ENABLE_CLAMAV=1
      - ENABLE_FAIL2BAN=1
      - ENABLE_POSTGREY=1
      - ONE_DIR=1
      - DMS_DEBUG=0
      - ENABLE_LDAP=1
      - LDAP_SERVER_HOST=ldap # your ldap container/IP/ServerName
      - LDAP_SEARCH_BASE=ou=people,dc=localhost,dc=localdomain
      - LDAP_BIND_DN=cn=admin,dc=localhost,dc=localdomain
      - LDAP_BIND_PW=admin
      - LDAP_QUERY_FILTER_USER=(&(mail=%s)(mailEnabled=TRUE))
      - LDAP_QUERY_FILTER_GROUP=(&(mailGroupMember=%s)(mailEnabled=TRUE))
      - LDAP_QUERY_FILTER_ALIAS=(|(&(mailAlias=%s)(objectClass=PostfixBookMailForward))(&(mailAlias=%s)(objectClass=PostfixBookMailAccount)(mailEnabled=TRUE)))
      - LDAP_QUERY_FILTER_DOMAIN=(|(&(mail=*@%s)(objectClass=PostfixBookMailAccount)(mailEnabled=TRUE))(&(mailGroupMember=*@%s)(objectClass=PostfixBookMailAccount)(mailEnabled=TRUE))(&(mailalias=*@%s)(objectClass=PostfixBookMailForward)))
      - DOVECOT_PASS_FILTER=(&(objectClass=PostfixBookMailAccount)(uniqueIdentifier=%n))
      - DOVECOT_USER_FILTER=(&(objectClass=PostfixBookMailAccount)(uniqueIdentifier=%n))
      - ENABLE_SASLAUTHD=1
      - SASLAUTHD_MECHANISMS=ldap
      - SASLAUTHD_LDAP_SERVER=ldap
      - SASLAUTHD_LDAP_BIND_DN=cn=admin,dc=localhost,dc=localdomain
      - SASLAUTHD_LDAP_PASSWORD=admin
      - SASLAUTHD_LDAP_SEARCH_BASE=ou=people,dc=localhost,dc=localdomain
      - POSTMASTER_ADDRESS=postmaster@localhost.localdomain
      - POSTFIX_MESSAGE_SIZE_LIMIT=100000000
    cap_add:
      - NET_ADMIN
      - SYS_PTRACE

volumes:
  maildata:
    driver: local
  mailstate:
    driver: local
  maillogs:
    driver: local
```


## General

##### DMS_DEBUG

  - **0** => Debug disabled
  - 1 => Enables debug on startup

##### ENABLE_CLAMAV

  - **0** => Clamav is disabled
  - 1 => Clamav is enabled

##### ONE_DIR

  - **0** => state in default directories
  - 1 => consolidate all states into a single directory (`/var/mail-state`) to allow persistence using docker volumes

##### ENABLE_POP3

  - **empty** => POP3 service disabled
  - 1 => Enables POP3 service

##### ENABLE_FAIL2BAN

  - **0** => fail2ban service disabled
  - 1 => Enables fail2ban service

If you enable Fail2Ban, don't forget to add the following lines to your `docker-compose.yml`:

    cap_add:
      - NET_ADMIN

Otherwise, `iptables` won't be able to ban IPs.

##### SMTP_ONLY

  - **empty** => all daemons start
  - 1 => only launch postfix smtp

##### SSL_TYPE

  - **empty** => SSL disabled
  - letsencrypt => Enables Let's Encrypt certificates
  - custom => Enables custom certificates
  - manual => Let you manually specify locations of your SSL certificates for non-standard cases
  - self-signed => Enables self-signed certificates
  - _any other value_ => SSL required, settings by default

##### TLS_LEVEL

  - **empty** => modern
  - modern => Enables TLSv1.2 and modern ciphers only. (default)
  - intermediate => Enables TLSv1, TLSv1.1 and TLSv1.2 and broad compatibility ciphers.
  - old => NOT implemented. If you really need it, then customize the TLS ciphers overriding postfix and dovecot settings.

##### SPOOF_PROTECTION
Configures the handling of creating mails with forged sender addresses.
  - **empty** => Mail address spoofing allowed. Any logged in user may create email messages with a forged sender address. See also [Wikipedia](https://en.wikipedia.org/wiki/Email_spoofing)(not recommended, but default for backwards compatibility reasons)
  - 1 => (recommended) Mail spoofing denied. Each user may only send with his own or his alias addresses. Addresses with [extension delimiters](http://www.postfix.org/postconf.5.html#recipient_delimiter) are not able to send messages.

##### ENABLE_SRS
Enables the Sender Rewriting Scheme. SRS is needed if your mail server acts as forwarder. See [postsrsd](https://github.com/roehling/postsrsd/blob/master/README.md#sender-rewriting-scheme-crash-course) for further explanation.
  - **0** => Disabled
  - 1 => Enabled

##### PERMIT_DOCKER

Set different options for mynetworks option (can be overwrite in postfix-main.cf) **WARNING**: Adding the docker network's gateway to the list of trusted hosts, e.g. using the `network` or `connected-networks` option, can create an [**open relay**](https://en.wikipedia.org/wiki/Open_mail_relay), if IPv6 is enabled on the host machine but not in Docker.
  - **empty** => localhost only
  - host => Add docker host (ipv4 only)
  - network => Add the docker default bridge network (172.16.0.0/12); **WARNING**: `docker-compose` might use others (e.g. 192.168.0.0/16) use `PERMIT_DOCKER=connected-networks` in this case
  - connected-networks => Add all connected docker networks (ipv4 only)

Note: you probably want to [set `POSTFIX_INET_PROTOCOLS=ipv4`](#postfix_inet_protocols) to make it work fine with Docker.

##### VIRUSMAILS_DELETE_DELAY

Set how many days a virusmail will stay on the server before being deleted
  - **empty** => 7 days


##### ENABLE_POSTFIX_VIRTUAL_TRANSPORT

This Option is activating the Usage of POSTFIX_DAGENT to specify a ltmp client different from default dovecot socket.

- **empty** => disabled
- 1 => enabled

##### POSTFIX_DAGENT

Enabled by ENABLE_POSTFIX_VIRTUAL_TRANSPORT. Specify the final delivery of postfix

- **empty**: fail
- `lmtp:unix:private/dovecot-lmtp` (use socket)
- `lmtps:inet:<host>:<port>` (secure lmtp with starttls, take a look at https://sys4.de/en/blog/2014/11/17/sicheres-lmtp-mit-starttls-in-dovecot/)
- `lmtp:<kopano-host>:2003` (use kopano as mailstore)
- etc.

##### POSTFIX\_MAILBOX\_SIZE\_LIMIT

Set the mailbox size limit for all users. If set to zero, the size will be unlimited (default).

- **empty** => 0 (no limit)


##### ENABLE_QUOTAS

- **1** => Dovecot quota is enabled
- 0 => Dovecot quota is disabled
  

##### POSTFIX\_MESSAGE\_SIZE\_LIMIT

Set the message size limit for all users. If set to zero, the size will be unlimited (not recommended!)

- **empty** => 10240000 (~10 MB)

##### ENABLE_MANAGESIEVE

  - **empty** => Managesieve service disabled
  - 1 => Enables Managesieve on port 4190

##### OVERRIDE_HOSTNAME

  - **empty** => uses the `hostname` command to get the mail server's canonical hostname
  - => Specify a fully-qualified domainname to serve mail for.  This is used for many of the config features so if you can't set your hostname (e.g. you're in a container platform that doesn't let you) specify it in this environment variable.

##### POSTMASTER_ADDRESS

  - **empty** => postmaster@domain.com
  - => Specify the postmaster address


##### POSTSCREEN_ACTION

  - **enforce** => Allow other tests to complete. Reject attempts to deliver mail with a 550 SMTP reply, and log the helo/sender/recipient information. Repeat this test the next time the client connects.
  - drop => Drop the connection immediately with a 521 SMTP reply. Repeat this test the next time the client connects.
  - ignore => Ignore the failure of this test. Allow other tests to complete. Repeat this test the next time the client connects. This option is useful for testing and collecting statistics without blocking mail.

##### DOVECOT_MAILBOX_FORMAT

  - **maildir** => uses very common Maildir format, one file contains one message
  - sdbox => (experimental) uses Dovecot high-performance mailbox format, one file contains one message
  - mdbox ==> (experimental) uses Dovecot high-performance mailbox format, multiple messages per file and multiple files per box

This option has been added in November 2019. Using other format than Maildir is considered as experimental in docker-mailserver and should only be used for testing purpose. For more details, please refer to [Dovecot Documentation](https://wiki2.dovecot.org/MailboxFormat).

##### POSTFIX_INET_PROTOCOLS

- **all** => All possible protocols.
- ipv4 => Use only IPv4 traffic. Most likely you want this behind Docker.
- ipv6 => Use only IPv6 traffic.

Note: More details in http://www.postfix.org/postconf.5.html#inet_protocols

## Reports

##### PFLOGSUMM_TRIGGER

  Enables regular pflogsumm mail reports.
  - **not set** => No report
  - daily_cron => Daily report for the previous day
  - logrotate => Full report based on the mail log when it is rotated

This is a new option. The old REPORT options are still supported for backwards compatibility.
If this is not set and reports are enabled with the old options, logrotate will be used.

##### PFLOGSUMM_RECIPIENT

  Recipient address for pflogsumm reports.
  - **not set** => Use REPORT_RECIPIENT or POSTMASTER_ADDRESS
  - => Specify the recipient address(es)

##### PFLOGSUMM_SENDER

  From address for pflogsumm reports.
  - **not set** => Use REPORT_SENDER or POSTMASTER_ADDRESS
  - => Specify the sender address

##### LOGWATCH_INTERVAL

  Interval for logwatch report.
  - **none** => No report is generated
  - daily => Send a daily report
  - weekly => Send a report every week

##### LOGWATCH_RECIPIENT

  Recipient address for logwatch reports if they are enabled.
  - **not set** => Use REPORT_RECIPIENT or POSTMASTER_ADDRESS
  - => Specify the recipient address(es)

##### REPORT_RECIPIENT (deprecated)

  Enables a report being sent (created by pflogsumm) on a regular basis.
  - **0** => Report emails are disabled unless enabled by other options
  - 1 => Using POSTMASTER_ADDRESS as the recipient
  - => Specify the recipient address

##### REPORT_SENDER (deprecated)

  Change the sending address for mail report
  - **empty** => mailserver-report@hostname
  - => Specify the report sender (From) address

##### REPORT_INTERVAL (deprecated)

  changes the interval in which logs are rotated and a report is being sent (deprecated).
  - **daily** => Send a daily report
  - weekly => Send a report every week
  - monthly => Send a report every month

Note: This variable used to control logrotate inside the container and sent the pflogsumm report when the logs were rotated.
It is still supported for backwards compatibility, but the new option LOGROTATE_INTERVAL has been added that only rotates
the logs.

##### LOGROTATE_INTERVAL

  Defines the interval in which the mail log is being rotated.
  - **daily** => Rotate daily.
  - weekly => Rotate weekly.
  - monthly => Rotate monthly.

Note that only the log inside the container is affected.
The full log output is still available via `docker logs mail` (or your respective container name).
If you want to control logrotation for the docker generated logfile see: [Docker Logging Drivers](https://docs.docker.com/config/containers/logging/configure/).

Also note that by default the logs are lost when the container is recycled. To keep the logs, mount a volume.

Finally the logrotate interval **may** affect the period for generated reports. That is the case when the reports are triggered by log rotation.

## Spamassassin

##### ENABLE_SPAMASSASSIN


  - **0** => Spamassassin is disabled
  - 1 => Spamassassin is enabled

**/!\\ Spam delivery:** when Spamassassin is enabled, messages marked as spam WILL NOT BE DELIVERED. 
Use `SPAMASSASSIN_SPAM_TO_INBOX=1` for receiving spam messages.

##### SPAMASSASSIN_SPAM_TO_INBOX


  - **0** => Spam messages will be bounced (_rejected_) without any notification (_dangerous_).
  - 1 => Spam messages will be delivered to the inbox and tagged as spam using `SA_SPAM_SUBJECT`.

##### MOVE_SPAM_TO_JUNK

  - **1** => Spam messages will be delivered in the `Junk` folder.
  - 0 => Spam messages will be delivered in the mailbox.

Note: this setting needs `SPAMASSASSIN_SPAM_TO_INBOX=1`

##### SA_TAG

  - **2.0** => add spam info headers if at, or above that level

Note: this spamassassin setting needs `ENABLE_SPAMASSASSIN=1`

##### SA_TAG2

  - **6.31** => add 'spam detected' headers at that level

Note: this spamassassin setting needs `ENABLE_SPAMASSASSIN=1`

##### SA_KILL

  - **6.31** => triggers spam evasive actions

Note: this spamassassin setting needs `ENABLE_SPAMASSASSIN=1`. By default, the mailserver is configured to quarantine spam emails. If emails are quarantined, they are compressed and stored in a location dependent on the ONE_DIR setting above. If `ONE_DIR=1` the location is /var/mail-state/lib-amavis/virusmails/. If `ONE_DIR=0` it is /var/lib/amavis/virusmails/. These paths are inside the docker container. To inhibit this behaviour and deliver spam emails, set this to a very high value e.g. 100.0.

##### SA_SPAM_SUBJECT

  - **\*\*\*SPAM\*\*\*** => add tag to subject if spam detected

Note: this spamassassin setting needs `ENABLE_SPAMASSASSIN=1`

##### SA_SHORTCIRCUIT_BAYES_SPAM

  - **1** => will activate spamassassin short circuiting for bayes spam detection.

This will uncomment the respective line in ```/etc/spamassasin/local.cf```

Note: activate this only if you are confident in your bayes database for identifying spam.

##### SA_SHORTCIRCUIT_BAYES_HAM

  - **1** => will activate spamassassin short circuiting for bayes ham detection

This will uncomment the respective line in ```/etc/spamassasin/local.cf```

Note: activate this only if you are confident in your bayes database for identifying ham.

## Fetchmail

##### ENABLE_FETCHMAIL
  - **0** => `fetchmail` disabled
  - 1 => `fetchmail` enabled

##### FETCHMAIL_POLL
  - **300** => `fetchmail` The number of seconds for the interval

## LDAP

##### ENABLE_LDAP

  - **empty** => LDAP authentification is disabled
  - 1 => LDAP authentification is enabled
  - NOTE:
    - A second container for the ldap service is necessary (e.g. [docker-openldap](https://github.com/osixia/docker-openldap))
    - For preparing the ldap server to use in combination with this container [this](http://acidx.net/wordpress/2014/06/installing-a-mailserver-with-postfix-dovecot-sasl-ldap-roundcube/) article may be helpful

##### LDAP_START_TLS

  - **empty** => no
  - yes => LDAP over TLS enabled for Postfix

##### LDAP_SERVER_HOST

  - **empty** => mail.domain.com
  - => Specify the dns-name/ip-address where the ldap-server
  - NOTE: If you going to use the mailserver in combination with docker-compose you can set the service name here

##### LDAP_SEARCH_BASE

  - **empty** => ou=people,dc=domain,dc=com
  - => e.g. LDAP_SEARCH_BASE=dc=mydomain,dc=local

##### LDAP_BIND_DN

  - **empty** => cn=admin,dc=domain,dc=com
  - => take a look at examples of SASL_LDAP_BIND_DN

##### LDAP_BIND_PW

  - **empty** => admin
  - => Specify the password to bind against ldap

##### LDAP_QUERY_FILTER_USER

  - e.g. `(&(mail=%s)(mailEnabled=TRUE))`
  - => Specify how ldap should be asked for users

##### LDAP_QUERY_FILTER_GROUP

  - e.g. `(&(mailGroupMember=%s)(mailEnabled=TRUE))`
  - => Specify how ldap should be asked for groups

##### LDAP_QUERY_FILTER_ALIAS

  - e.g. `(&(mailAlias=%s)(mailEnabled=TRUE))`
  - => Specify how ldap should be asked for aliases

##### LDAP_QUERY_FILTER_DOMAIN

- e.g. `(&(|(mail=*@%s)(mailalias=*@%s)(mailGroupMember=*@%s))(mailEnabled=TRUE))`
- => Specify how ldap should be asked for domains

##### DOVECOT_TLS

  - **empty** => no
  - yes => LDAP over TLS enabled for Dovecot

## Dovecot

The following variables overwrite the default values for ```/etc/dovecot/dovecot-ldap.conf.ext```.

##### DOVECOT_USER_FILTER

  - e.g. `(&(objectClass=PostfixBookMailAccount)(uniqueIdentifier=%n))`

##### DOVECOT_USER_ATTRS

 - e.g. `homeDirectory=home,qmailUID=uid,qmailGID=gid,mailMessageStore=mail`
 - => Specify the directory to dovecot attribute mapping that fits your directory structure.
 - Note: This is necessary for directories that do not use the [Postfix Book Schema](test/docker-openldap/bootstrap/schema/mmc/postfix-book.schema).
 - Note: The left-hand value is the directory attribute, the right hand value is the dovecot variable.
 - More details on the [Dovecot Wiki](https://wiki.dovecot.org/AuthDatabase/LDAP/Userdb)

##### DOVECOT_PASS_FILTER

  - e.g. `(&(objectClass=PostfixBookMailAccount)(uniqueIdentifier=%n))`

##### DOVECOT_PASS_ATTRS

- e.g. `uid=user,userPassword=password`
- => Specify the directory to dovecot variable mapping that fits your directory structure.
- Note: This is necessary for directories that do not use the [Postfix Book Schema](test/docker-openldap/bootstrap/schema/mmc/postfix-book.schema).
- Note: The left-hand value is the directory attribute, the right hand value is the dovecot variable.
- More details on the [Dovecot Wiki](https://wiki.dovecot.org/AuthDatabase/LDAP/PasswordLookups)

## Postgrey

##### ENABLE_POSTGREY

  - **0** => `postgrey` is disabled
  - 1 => `postgrey` is enabled

##### POSTGREY_DELAY

  - **300** => greylist for N seconds

Note: This postgrey setting needs `ENABLE_POSTGREY=1`

##### POSTGREY_MAX_AGE

  - **35** => delete entries older than N days since the last time that they have been seen

Note: This postgrey setting needs `ENABLE_POSTGREY=1`

##### POSTGREY_AUTO_WHITELIST_CLIENTS

  - **5** => whitelist host after N successful deliveries (N=0 to disable whitelisting)

Note: This postgrey setting needs `ENABLE_POSTGREY=1`

##### POSTGREY_TEXT

  - **Delayed by postgrey** => response when a mail is greylisted

Note: This postgrey setting needs `ENABLE_POSTGREY=1`

## SASL Auth

##### ENABLE_SASLAUTHD

  - **0** => `saslauthd` is disabled
  - 1 => `saslauthd` is enabled

##### SASLAUTHD_MECHANISMS

  - empty => pam
  - `ldap` => authenticate against ldap server
  - `shadow` => authenticate against local user db
  - `mysql` => authenticate against mysql db
  - `rimap` => authenticate against imap server
  - NOTE: can be a list of mechanisms like pam ldap shadow

##### SASLAUTHD_MECH_OPTIONS

  - empty => None
  - e.g. with SASLAUTHD_MECHANISMS rimap you need to specify the ip-address/servername of the imap server  ==> xxx.xxx.xxx.xxx

##### SASLAUTHD_LDAP_SERVER

  - empty => localhost

##### SASLAUTHD_LDAP_SSL

  - empty or 0 => `ldap://` will be used
  - 1 => `ldaps://` will be used

##### SASLAUTHD_LDAP_BIND_DN

  - empty => anonymous bind
  - specify an object with privileges to search the directory tree
  - e.g. active directory: SASLAUTHD_LDAP_BIND_DN=cn=Administrator,cn=Users,dc=mydomain,dc=net
  - e.g. openldap: SASLAUTHD_LDAP_BIND_DN=cn=admin,dc=mydomain,dc=net

##### SASLAUTHD_LDAP_PASSWORD

  - empty => anonymous bind

##### SASLAUTHD_LDAP_SEARCH_BASE

  - empty => Reverting to SASLAUTHD_MECHANISMS pam
  - specify the search base

##### SASLAUTHD_LDAP_FILTER

  - empty => default filter `(&(uniqueIdentifier=%u)(mailEnabled=TRUE))`
  - e.g. for active directory: `(&(sAMAccountName=%U)(objectClass=person))`
  - e.g. for openldap: `(&(uid=%U)(objectClass=person))`

##### SASL_PASSWD

  - **empty** => No sasl_passwd will be created
  - string => `/etc/postfix/sasl_passwd` will be created with the string as password

## SRS (Sender Rewriting Scheme)

##### SRS_SENDER_CLASSES

An email has an "envelope" sender (indicating the sending server) and a
"header" sender (indicating who sent it). More strict SPF policies may require
you to replace both instead of just the envelope sender.

[More info](https://www.mybluelinux.com/what-is-email-envelope-and-email-header/).

  - **envelope_sender** => Rewrite only envelope sender address
  - header_sender => Rewrite only header sender (not recommended)
  - envelope_sender,header_sender => Rewrite both senders

##### SRS_EXCLUDE_DOMAINS

  - **empty** => Envelope sender will be rewritten for all domains
  - provide comma separated list of domains to exclude from rewriting

##### SRS_SECRET

  - **empty** => generated when the container is started for the first time
  - provide a secret to use in base64
  - you may specify multiple keys, comma separated. the first one is used for signing and the remaining will be used for verification. this is how you rotate and expire keys
  - if you have a cluster/swarm make sure the same keys are on all nodes
  - example command to generate a key: `dd if=/dev/urandom bs=24 count=1 2>/dev/null | base64`

##### SRS_DOMAINNAME

  - **empty** => Derived from OVERRIDE_HOSTNAME, DOMAINNAME, or the container's hostname
  - Set this if auto-detection fails, isn't what you want, or you wish to have a separate container handle DSNs

## Default Relay Host

#### DEFAULT_RELAY_HOST

  - **empty** => don't set default relayhost setting in main.cf
  - default host and port to relay all mail through.
    Format: `[example.com]:587` (don't forget the brackets if you need this to
    be compatible with `$RELAY_USER` and `$RELAY_PASSWORD`, explained below).

## Multi-domain Relay Hosts

#### RELAY_HOST

  - **empty** => don't configure relay host
  - default host to relay mail through

#### RELAY_PORT

  - **empty** => 25
  - default port to relay mail through

#### RELAY_USER

  - **empty** => no default
  - default relay username (if no specific entry exists in postfix-sasl-password.cf)

#### RELAY_PASSWORD

  - **empty** => no default
  - password for default relay user